{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dict()\n",
    "def extractdata(address):\n",
    "    for file in os.listdir(address):\n",
    "        cnt_category = 0\n",
    "        if(str(file)[0] != '.'):\n",
    "            print(\"=====Category======\")\n",
    "            category_name = file\n",
    "            train_dir = address + '/' + category_name\n",
    "            cnt_category += 1\n",
    "            print(category_name)\n",
    "            print(\"------------------\")\n",
    "            make_Dictionary(train_dir)\n",
    "            # print(os.listdir(category_name))\n",
    "    print(\"===================\")\n",
    "    vocab_size = len(dictionary)\n",
    "    print(vocab_size)\n",
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]\n",
    "    for email in emails:\n",
    "        # print(email) ## ex. mails/Spams/virus.txt\n",
    "        with open(email) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i != 1: #Bodt of email is only 2 line of text file\n",
    "                    words = line\n",
    "                    pattern3 = re.compile(\"[^\\w\\d]+\")\n",
    "                    words = pattern3.sub(' ',words)\n",
    "                    # print(words)\n",
    "                    dicts = words.split()\n",
    "                    count = collections.Counter(dicts).most_common()\n",
    "                    for word, _ in count:\n",
    "                        dictionary[word] = len(dictionary)\n",
    "                    # print(dictionary)\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "def concise(dictionary):\n",
    "    list_to_remove = dictionary.keys()\n",
    "    for item in list_to_remove:\n",
    "        if item.isalpha() == False: \n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Category======\n",
      "Spams\n",
      "------------------\n",
      "virus \n",
      " \n",
      "I m putting around 4 million different keys into a Python dictionary Creating this dictionary takes about 15 minutes and consumes about 4GB of memory on my machine After the dictionary is fully created querying the dictionary is fast \n",
      " \n",
      "I suspect that dictionary creation is so resource consuming as the dictionary is very often rehashed as it grows enormously Is is possible to create a dictionary in Python with some initial size or bucket number \n",
      " \n",
      "My dictionary points from a number to an object \n",
      "=====Category======\n",
      "Ads\n",
      "------------------\n",
      "This is not an advertisement the alcohol in ABC market is only 10 \n",
      "The final date is 2017 Oct 2 \n",
      " \n",
      "Jix Jix Jix \n",
      " \n",
      " \n",
      "This article is an update to my original article on Celgene CELG published on June 22 2017 Celgene reported its financial results yesterday October 26 2017 and although the quarter was good lowered guidance crushed the stock price In my opinion some of the sag in price was justified but for the most part an overreaction Celgene is still a fast growing company and I believe that current valuation is in alignment with the company s true worth Therefore I believe the company continues to offer the long term oriented growth investor with potentially attractive returns \n",
      " \n",
      "Nevertheless although Celgene did lower future guidance out to 2020 it is still forecasting high future growth just not quite as high as previously Therefore I thought it would be useful to provide an updated forecasting video on Celgene with the lowered guidance figures included Hopefully this will assist Celgene investors with formulating a clearer perspective on what the long term impacts of this lowered guidance might really mean I believe you will find that the fear appears greater than the reality \n",
      "=====Category======\n",
      "Hams\n",
      "------------------\n",
      "long ago the mice had a general council to consider what measures they could take to outwit their common enemy the cat some said this and some said that but at last a young mouse got up and said he had a proposal to make which he thought would meet the case you will all agree said he that our chief danger consists in the sly and treacherous manner in which the enemy approaches us now if we could receive some signal of her approach we could easily escape from her i venture therefore to propose that a small bell be procured and attached by a ribbon round the neck of the cat by this means we should always know when she was about and could easily retire while she was in the neighbourhood this proposal met with general applause until an old mouse got up and said that is all very well but who is to bell the cat the mice looked at one another and nobody spoke then the old mouse said it is easy to propose impossible remedies \n",
      " \n",
      " Truly successful growth stocks are capable of producing game changing long term returns for investors Nevertheless investing in growth stocks can be tricky and price action very volatile in the short run Moreover a true fast growing business is capable of supporting higher P E ratios than traditional blue chip dividend paying stocks However from a valuation perspective it s important that investors recognize that the P E ratio of a growth stock should be relative to and related to its earnings growth potential \n",
      " \n",
      " Wall Street has generated the acronym GARP Growth At a Reasonable Price for valuing growth stocks It is a fact that you can pay higher valuations for growth stocks but even with growth stocks valuations need to be reasonable enough to support future returns that are commensurate with the risk associated with investing in them When investing in growth stocks the future is more important than the past \n",
      "hello the inicients \n",
      "SKT is godlike in this world championship don t you think and \n",
      " \n",
      "FW and AHQ stops at top 16 both teams are from Taiwan Good luck to them \n",
      "===================\n",
      "337\n"
     ]
    }
   ],
   "source": [
    "directory = 'mails'\n",
    "extractdata(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-ac3cb2c5120e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Just use 'w' mode in 3.x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/csv.py\u001b[0m in \u001b[0;36mwriteheader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/csv.py\u001b[0m in \u001b[0;36mwriterow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "with open('my_data.csv', 'wb') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.DictWriter(f, dictionary.keys())\n",
    "    w.writerow(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
